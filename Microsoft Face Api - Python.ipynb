{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Face Api Integration through Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build facial recognition software into your applications with the Face API from Microsoft Azure. Detect, identify and verify faces with this powerful API. I will try to integrate these APIs through python. For this, I will create a small face dataset of all the characters of our favorite sitcom F.R.I.E.N.D.S. I will use this dataset to identify whether the image provided by me belongs to which character. The same logic can be used for creating projects like Attendance management, visitor management, access control etc with facial recognition.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with running the most basic of these APIs: Face - Detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face - Detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detects human faces in an image, return face rectangles, and optionally with faceIds, landmarks, and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE:[{'faceId': '2bed5571-71e8-4930-9fae-b2ba46db077d', 'faceRectangle': {'top': 335, 'left': 249, 'width': 319, 'height': 319}, 'faceAttributes': {'smile': 1.0, 'headPose': {'pitch': 0.0, 'roll': -3.7, 'yaw': -2.6}, 'gender': 'male', 'age': 43.0, 'facialHair': {'moustache': 0.1, 'beard': 0.1, 'sideburns': 0.1}}}]\n"
     ]
    }
   ],
   "source": [
    "# Request headers set Subscription key which provides access to this API. Found in your Cognitive Services accounts.\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Key': 'XXXad1b1f6564XXXXed71a61f7XXXb44',\n",
    "}\n",
    "\n",
    "body = dict()\n",
    "body[\"url\"] = \"http://www.imagozone.com/var/albums/vedete/Matthew%20Perry/Matthew%20Perry.jpg?m=1355670659\"\n",
    "body = str(body)\n",
    "\n",
    "# Request URL \n",
    "FaceApiDetect = 'https://westus.api.cognitive.microsoft.com/face/v1.0/detect?returnFaceId=true&returnFaceAttributes=age,gender,headPose,smile,facialHair' \n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.post(FaceApiDetect, data=body, headers=headers) \n",
    "    print(\"RESPONSE:\" + str(response.json()))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A successful call returns an array of face entries ranked by face rectangle size in descending order. An empty response indicates no faces detected. A face entry may contain the following values depending on input parameters: faceId, faceRectangle, faceAttributes, etc. Matthew Perry AKA chandler seems to be smiling in this photo, API has got that right but not so sure about his age.\n",
    "\n",
    "Alright, now to our original problem statement. The first step is to create a database of face images of all our friend's characters and train a model. Which we will use later to identify our friends characters from any given face image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a person group using Face API:  PersonGroup - Create\n",
    "\n",
    "Create a new person group with specified personGroupId, name, and user-provided userData. \n",
    "A person group is the container of the uploaded person data, including face images and face recognition features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE:200\n"
     ]
    }
   ],
   "source": [
    "personGroupId=\"friends\"\n",
    "\n",
    "body = dict()\n",
    "body[\"name\"] = \"F.R.I.E.N.D.S\"\n",
    "body[\"userData\"] = \"All friends cast\"\n",
    "body = str(body)\n",
    "\n",
    "#Request URL \n",
    "FaceApiCreateLargePersonGroup = 'https://westus.api.cognitive.microsoft.com/face/v1.0/persongroups/'+personGroupId \n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.put(FaceApiCreateLargePersonGroup, data=body, headers=headers) \n",
    "    print(\"RESPONSE:\" + str(response.status_code))\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a person using face API: PersonGroup Person - Create\n",
    "\n",
    "Create a new person in a specified person group. This will return a personId which we will use in the next step to add training face images to this person. we can also save some additional metadata for each person like a name. We will do chandler first because he is, after all, everyone's favorite character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSONID: cd337328-4a7b-4316-aba8-91f7d7886bfb\n"
     ]
    }
   ],
   "source": [
    "body = dict()\n",
    "body[\"name\"] = \"Chandler\"\n",
    "body[\"userData\"] = \"Friends\"\n",
    "body = str(body)\n",
    "\n",
    "#Request URL \n",
    "FaceApiCreatePerson = 'https://westus.api.cognitive.microsoft.com/face/v1.0/persongroups/'+personGroupId+'/persons' \n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.post(FaceApiCreatePerson, data=body, headers=headers) \n",
    "    responseJson = response.json()\n",
    "    personId = responseJson[\"personId\"]\n",
    "    print(\"PERSONID: \"+str(personId))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add face images to the person using face API: PersonGroup Person - Add Face\n",
    "\n",
    "Add a face image to a person into a person group for face identification or verification. To deal with the image of multiple faces, input face can be specified as an image with a targetFace rectangle. It returns a persistedFaceId representing the added face. The extracted face feature, instead of the actual image, will be stored on the server until PersonGroup PersonFace - Delete, PersonGroup Person - Delete or PersonGroup - Delete is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSISTED FACE ID: 4093cdd9-2fa1-4d7f-8d7a-09d7488ddc9f\n",
      "PERSISTED FACE ID: 087e27db-9c06-4f1d-9e10-1099fc5bc091\n",
      "PERSISTED FACE ID: a4abe7a0-7619-4841-addb-ae7d5421fa57\n",
      "PERSISTED FACE ID: 57873f5c-1fa6-44db-8f93-b6d32b9ab102\n",
      "PERSISTED FACE ID: acf36ddb-62ad-4a43-9194-5ca05b0e6228\n"
     ]
    }
   ],
   "source": [
    "chandlerImageList = [\"http://www.imagozone.com/var/albums/vedete/Matthew%20Perry/Matthew%20Perry.jpg?m=1355670659\",\n",
    "                     \"https://i.pinimg.com/236x/b0/57/ff/b057ff0d16bd5205e4d3142e10f03394--muriel-matthew-perry.jpg\",\n",
    "                     \"https://qph.fs.quoracdn.net/main-qimg-74677a162a39c79d6a9aa2b11cc195b1\",\n",
    "                     \"https://pbs.twimg.com/profile_images/2991381736/e2160154f215a325b0fc73f866039311_400x400.jpeg\",\n",
    "                     \"https://i.pinimg.com/236x/f2/9f/45/f29f45049768ddf5c5d75ff37ffbfb3f--hottest-actors-matthew-perry.jpg\"]\n",
    "\n",
    "#Request URL \n",
    "FaceApiCreatePerson = 'https://westus.api.cognitive.microsoft.com/face/v1.0/persongroups/'+personGroupId+'/persons/'+personId+'/persistedFaces' \n",
    "\n",
    "for image in chandlerImageList:\n",
    "    body = dict()\n",
    "    body[\"url\"] = image\n",
    "    body = str(body)\n",
    "\n",
    "    try:\n",
    "        # REST Call \n",
    "        response = requests.post(FaceApiCreatePerson, data=body, headers=headers) \n",
    "        responseJson = response.json()\n",
    "        persistedFaceId = responseJson[\"persistedFaceId\"]\n",
    "        print(\"PERSISTED FACE ID: \"+str(persistedFaceId))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: Repeat the step 2 and 3 to add  face images of the remaining characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4:  Train the model using face API: PersonGroup - Train\n",
    "\n",
    "Submit a person group training task. Training is a crucial step that only a trained person group can be used by Face - Identify. \n",
    "\n",
    "The training task is an asynchronous task. Training time depends on the number of person entries, and their faces in a person group. It could be several seconds to minutes. To check training status, please use PersonGroup - Get Training Status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE:202\n"
     ]
    }
   ],
   "source": [
    "body = dict()\n",
    "\n",
    "#Request URL \n",
    "FaceApiTrain = 'https://westus.api.cognitive.microsoft.com/face/v1.0/persongroups/'+personGroupId+'/train'\n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.post(FaceApiTrain, data=body, headers=headers) \n",
    "    print(\"RESPONSE:\" + str(response.status_code))\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:  Final Step Identify face image. This involves in total 3 face Apis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 First API: Face - Detect\n",
    "\n",
    "This will return a face Id which is valid for 24 hrs. This face id will be used by the next API to identify the character. Let's try to give new random chandlers face image and see if the model identifies it accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FACE ID: 8f1ec32d-60b3-4b86-a4d4-e8933463b734\n"
     ]
    }
   ],
   "source": [
    "body = dict()\n",
    "body[\"url\"] = \"https://upload.wikimedia.org/wikipedia/en/thumb/6/6c/Matthew_Perry_as_Chandler_Bing.jpg/220px-Matthew_Perry_as_Chandler_Bing.jpg\"\n",
    "body = str(body)\n",
    "\n",
    "# Request URL \n",
    "FaceApiDetect = 'https://westus.api.cognitive.microsoft.com/face/v1.0/detect?returnFaceId=true' \n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.post(FaceApiDetect, data=body, headers=headers) \n",
    "    responseJson = response.json()\n",
    "    faceId = responseJson[0][\"faceId\"]\n",
    "    print(\"FACE ID: \"+str(faceId))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Second API: Face - Identify\n",
    "\n",
    "1-to-many identification to find the closest matches of the specific query person face from a person group. For each face in the faceIds array, Face Identify will compute similarities between the query face and all the faces in the person group (given by personGroupId), and return candidate person(s) for that face ranked by similarity confidence.\n",
    "\n",
    "This is will return the personId which we will use in the next optional step to find out the metadata stored with that person id like his name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON ID: cd337328-4a7b-4316-aba8-91f7d7886bfb, CONFIDENCE :0.79974\n"
     ]
    }
   ],
   "source": [
    "faceIdsList = [faceId]\n",
    "\n",
    "body = dict()\n",
    "body[\"personGroupId\"] = personGroupId\n",
    "body[\"faceIds\"] = faceIdsList\n",
    "body[\"maxNumOfCandidatesReturned\"] = 1 \n",
    "body[\"confidenceThreshold\"] = 0.5\n",
    "body = str(body)\n",
    "\n",
    "# Request URL \n",
    "FaceApiIdentify = 'https://westus.api.cognitive.microsoft.com/face/v1.0/identify' \n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.post(FaceApiIdentify, data=body, headers=headers) \n",
    "    responseJson = response.json()\n",
    "    personId = responseJson[0][\"candidates\"][0][\"personId\"]\n",
    "    confidence = responseJson[0][\"candidates\"][0][\"confidence\"]\n",
    "    print(\"PERSON ID: \"+str(personId)+ \", CONFIDENCE :\"+str(confidence))\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"Could not detect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Second Api: PersonGroup Person - Get\n",
    "\n",
    "Retrieve a person's name and userData, and the persisted faceIds representing the registered person face image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Is Chandler\n"
     ]
    }
   ],
   "source": [
    "# Request URL \n",
    "FaceApiGetPerson = 'https://westus.api.cognitive.microsoft.com/face/v1.0/persongroups/'+personGroupId+'/persons/'+personId\n",
    "\n",
    "try:\n",
    "    response = requests.get(FaceApiGetPerson, headers=headers) \n",
    "    responseJson = response.json()\n",
    "    print(\"This Is \"+str(responseJson[\"name\"]))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Could not detect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
